{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20474,
     "status": "ok",
     "timestamp": 1702224767954,
     "user": {
      "displayName": "pp rich",
      "userId": "00371241177131396451"
     },
     "user_tz": -480
    },
    "id": "8ZGfFvBIc5zD",
    "outputId": "95b97c95-a57f-40fc-9e6c-c8f7e51cdfd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6806,
     "status": "ok",
     "timestamp": 1702224774758,
     "user": {
      "displayName": "pp rich",
      "userId": "00371241177131396451"
     },
     "user_tz": -480
    },
    "id": "LAxxcmTYBPJh",
    "outputId": "1e682e88-d472-46c1-9a4f-41a18227820f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
      "Requirement already satisfied: typing_extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from polars) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fhZc9OKdHz0"
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMv0JvhR0zr1"
   },
   "outputs": [],
   "source": [
    "LOCALES = [\"UK\"]\n",
    "TOP_N = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4R4xsHc-ddr4"
   },
   "source": [
    "# Generate candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfBkGgPkdH3i"
   },
   "outputs": [],
   "source": [
    "product = pd.read_parquet(\"/content/drive/MyDrive/kddcup2023/data/preprocessed/common/product.parquet\")\n",
    "# train = pl.read_parquet(\"/content/drive/MyDrive/kddcup2023-master/data/preprocessed/task1/train_task1.parquet\")\n",
    "# test = pl.read_parquet(\"/content/drive/MyDrive/kddcup2023-master/data/preprocessed/task1/test_task1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45518154,
     "status": "ok",
     "timestamp": 1702270860973,
     "user": {
      "displayName": "pp rich",
      "userId": "00371241177131396451"
     },
     "user_tz": -480
    },
    "id": "akzCPjE8zx0b",
    "outputId": "e3baab74-8edc-4584-b3dc-1e95867c543b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start UK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500180/500180 [12:35:36<00:00, 11.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def calculate_similar_items(product_id):\n",
    "    # Retrieve the vector for the query product\n",
    "    query_vec = tfidf_matrix[df.index[df['id'] == product_id]][0]\n",
    "\n",
    "    # Calculate similarity and sort in descending order\n",
    "    similarity = cosine_similarity(tfidf_matrix, query_vec).flatten()\n",
    "    similarity_scores = pd.Series(similarity, index=df.index)\n",
    "    similarity_scores = similarity_scores.sort_values(ascending=False)\n",
    "\n",
    "    # Extract the top items with high similarity\n",
    "    similar_items = similarity_scores.iloc[1:TOP_N+1]\n",
    "    similar_items_ids = df.loc[similar_items.index][\"id\"].values\n",
    "    similar_items_scores = similar_items.values\n",
    "\n",
    "    return (product_id, similar_items_ids, similar_items_scores)\n",
    "\n",
    "\n",
    "for locale in LOCALES:\n",
    "    print(f\"start {locale}...\")\n",
    "    locales, items, candidate_items, similarity_scores = [], [], [], []\n",
    "\n",
    "    # Filter by locale\n",
    "    df = product[product[\"locale\"] == locale].reset_index()\n",
    "    product_ids = df[\"id\"].to_list()\n",
    "\n",
    "    # Create a TF-IDF vectorizer\n",
    "    tfidf = TfidfVectorizer()\n",
    "\n",
    "    # Create text data combining product information\n",
    "    text_data = df[\"title\"].fillna(\"\") + \" \" + df[\"color\"].fillna(\"\") + \" \" + df[\"size\"].fillna(\"\") + \" \" + \\\n",
    "                df[\"model\"].fillna(\"\") + \" \" + df[\"material\"].fillna(\"\") + \" \" + df[\"author\"].fillna(\"\") + \" \" + \\\n",
    "                df[\"brand\"].fillna(\"\") + \" \" + df[\"desc\"].fillna(\"\")\n",
    "\n",
    "    # Create a TF-IDF matrix\n",
    "    tfidf_matrix = tfidf.fit_transform(text_data)\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(calculate_similar_items, product_ids), total=len(product_ids)))\n",
    "\n",
    "    for result in results:\n",
    "        product_id, similar_items_ids, similar_items_scores = result\n",
    "\n",
    "        # Store the results\n",
    "        locales.extend([locale] * TOP_N)\n",
    "        items.extend([product_id] * TOP_N)\n",
    "        candidate_items.extend(list(similar_items_ids))\n",
    "        similarity_scores.extend(list(similar_items_scores))\n",
    "\n",
    "    # Convert the results to a dataframe\n",
    "    similar_products = pd.DataFrame({\n",
    "        \"locale\": locales,\n",
    "        \"item\": items,\n",
    "        \"candidate_item\": candidate_items,\n",
    "        \"similarity_score\": similarity_scores,\n",
    "    })\n",
    "\n",
    "    # Assign rank\n",
    "    similar_products = pl.from_pandas(similar_products)\n",
    "    similar_products = similar_products \\\n",
    "    .sort([\"item\", \"similarity_score\"], descending=[False, True]) \\\n",
    "    .with_columns(pl.col(\"similarity_score\").rank(descending=True, method=\"min\").over(\"item\").alias(\"similarity_rank\"))\n",
    "\n",
    "    # Output to file\n",
    "    file_name = f\"similar_products_10_{locale}.parquet\"\n",
    "    similar_products.write_parquet(\"/content/drive/MyDrive/kddcup2023/data/interim/candidates/task1/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcyP0XYxWg5N"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
