{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47597,
     "status": "ok",
     "timestamp": 1705161722466,
     "user": {
      "displayName": "王晓",
      "userId": "03118875830758001304"
     },
     "user_tz": -480
    },
    "id": "BnKnD-UQWSEg",
    "outputId": "b421dcbf-febe-416d-8725-a7f7b5b73635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6007,
     "status": "ok",
     "timestamp": 1705161728468,
     "user": {
      "displayName": "王晓",
      "userId": "03118875830758001304"
     },
     "user_tz": -480
    },
    "id": "8Af_47xxWVhC",
    "outputId": "2d5d8fb7-445f-4fa3-d8f5-7c600b9ea874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
      "Requirement already satisfied: typing_extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from polars) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-RBDJdwWdI-"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "from tqdm import tqdm\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YamzEAnvF6Sz"
   },
   "outputs": [],
   "source": [
    "WINDOW_N = 10\n",
    "WEIGHTS = {-10:0.01, -9:0.01, -8:0.01, -7:0.01, -6:0.01, -5:0.05, -4:0.05, -3:0.1, -2:0.25, -1:0.5, 1:3, \\\n",
    "2:0.5, 3:0.25, 4:0.1, 5:0.05, 6:0.01, 7:0.01, 8:0.01, 9:0.01, 10:0.01, }\n",
    "TOP_N = 200\n",
    "LOCALES = [\"DE\", \"UK\", \"JP\"]\n",
    "VER = \"30\"\n",
    "DIR = \"/content/drive/MyDrive/kddcup2023/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTqrjJF11A4n"
   },
   "outputs": [],
   "source": [
    "def preprocess(df:pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.explode([\"prev_items\"])\n",
    "    df = df.with_columns(\n",
    "        df.select(pl.col(\"session_id\").cumcount().over(\"session_id\").alias(\"sequence_num\"))\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-55dFNZvS1j"
   },
   "outputs": [],
   "source": [
    "def generate_co_visit_matrix(df: pl.DataFrame) -> pl.DataFrame:\n",
    "\n",
    "    # Count of occurrences for each item\n",
    "    item_count = df.groupby(\"prev_items\").count()\n",
    "\n",
    "    # Creation of co-occurrence pairs\n",
    "    df = df[[\"session_id\", \"prev_items\", \"sequence_num\"]].join(df[[\"session_id\", \"prev_items\", \"sequence_num\"]], on=\"session_id\")\n",
    "\n",
    "    # Calculate and filter the interval of co-occurrence\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"sequence_num_right\").cast(pl.Int64) - pl.col(\"sequence_num\").cast(pl.Int64)).alias(\"diff_sequence_num\")\n",
    "    )\n",
    "    df = df.filter(pl.col(\"diff_sequence_num\").abs() <= WINDOW_N)\n",
    "    df = df.filter(pl.col(\"prev_items\") != pl.col(\"prev_items_right\"))\n",
    "\n",
    "    # Calculate weights and sum for each co-occurrence pair\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"diff_sequence_num\").map_dict(WEIGHTS).alias(\"co_visit_weight\")\n",
    "    )\n",
    "    df = df.groupby([\"prev_items\", \"prev_items_right\"]).sum()\n",
    "\n",
    "    # Formatting\n",
    "    df = df.rename({\"prev_items\": \"item\", \"prev_items_right\": \"candidate_item\"})[[\"item\", \"candidate_item\", \"co_visit_weight\"]]\n",
    "\n",
    "    # Combine with counts of each item and calculate lift value\n",
    "    df = df.join(item_count, left_on=\"item\", right_on=\"prev_items\", how=\"left\").rename({\"count\": \"item_count\"})\n",
    "    df = df.join(item_count, left_on=\"candidate_item\", right_on=\"prev_items\", how=\"left\").rename({\"count\": \"candidate_item_count\"})\n",
    "    df = df.with_columns((pl.col(\"co_visit_weight\") / (pl.col(\"item_count\").sqrt() * pl.col(\"candidate_item_count\").sqrt())).alias(\"lift\"))\n",
    "\n",
    "    # Extract items with high lift values\n",
    "    df = df.sort([\"item\", \"lift\"], descending=[False, True])\n",
    "    df = df.groupby(\"item\", maintain_order=True).head(TOP_N)\n",
    "\n",
    "    return df[[\"item\", \"candidate_item\", \"lift\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDePQQB7E9A9"
   },
   "outputs": [],
   "source": [
    "def filter_by_locale_availability(co_visit_matrix:pl.DataFrame, product:pl.DataFrame):\n",
    "    product = product.unique(subset=[\"id\"])\n",
    "    product = product[[\"id\", \"available_locales\"]]\n",
    "    co_visit_matrix = co_visit_matrix.join(product, left_on=\"item\", right_on=\"id\", how=\"left\").rename({\"available_locales\":\"item_locales\"})\n",
    "    co_visit_matrix = co_visit_matrix.join(product, left_on=\"candidate_item\", right_on=\"id\", how=\"left\").rename({\"available_locales\":\"candidate_item_locales\"})\n",
    "    dfs = []\n",
    "    for locale in LOCALES:\n",
    "        df = co_visit_matrix.filter(pl.lit(locale).is_in(pl.col(\"item_locales\")) & pl.lit(locale).is_in(pl.col(\"candidate_item_locales\")))\n",
    "        df = df.with_columns(pl.lit(locale).alias(\"locale\"))\n",
    "        df = df[[\"item\", \"candidate_item\", \"lift\", \"locale\"]]\n",
    "        df = df.sort([\"item\", \"lift\"], descending=[False, True])\n",
    "        df = df.groupby(\"item\", maintain_order=True).head(TOP_N)\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"lift\").rank(descending=True, method=\"min\").over(\"item\").alias(\"lift_rank\")\n",
    "        )\n",
    "        dfs.append(df)\n",
    "    co_visit_matrix = pl.concat(dfs)\n",
    "    return co_visit_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSRUru1RZSeW"
   },
   "source": [
    "# For local train/eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kppiCZHz2kMb"
   },
   "outputs": [],
   "source": [
    "train1 = pl.read_parquet(DIR + \"data/preprocessed/task1/train_task1.parquet\")\n",
    "train2 = pl.read_parquet(DIR + \"data/preprocessed/task2/train_task2.parquet\")\n",
    "train1 = train1.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task1\").alias(\"session_id\")\n",
    ")\n",
    "train = pl.concat([train1, train2])\n",
    "\n",
    "test1_1 = pl.read_parquet(DIR + \"data/preprocessed/task1/test_task1_phase1.parquet\")\n",
    "test1_2 = pl.read_parquet(DIR + \"data/preprocessed/task1/test_task1_phase2.parquet\")\n",
    "test2_1 = pl.read_parquet(DIR + \"data/preprocessed/task2/test_task2_phase1.parquet\")\n",
    "test2_2 = pl.read_parquet(DIR + \"data/preprocessed/task2/test_task2_phase2.parquet\")\n",
    "test3_1 = pl.read_parquet(DIR + \"data/preprocessed/task3/test_task3_phase1.parquet\")\n",
    "test3_2 = pl.read_parquet(DIR + \"data/preprocessed/task3/test_task3_phase2.parquet\")\n",
    "test1_1 = test1_1.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task1\").alias(\"session_id\")\n",
    ")\n",
    "test1_2 = test1_2.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task1\").alias(\"session_id\")\n",
    ")\n",
    "test3_1 = test3_1.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task3\").alias(\"session_id\")\n",
    ")\n",
    "test3_2 = test3_2.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task3\").alias(\"session_id\")\n",
    ")\n",
    "test = pl.concat([test1_1, test1_2, test2_1, test2_2, test3_1, test3_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgtgFHKi0xy5"
   },
   "outputs": [],
   "source": [
    "\n",
    "train = preprocess(train)\n",
    "test = preprocess(test)\n",
    "session_df = pl.concat([\n",
    "    train[\"prev_items\", \"locale\", \"session_id\", \"sequence_num\"],\n",
    "    test[\"prev_items\", \"locale\", \"session_id\", \"sequence_num\"],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQ5wXFmjErFV"
   },
   "outputs": [],
   "source": [
    "product = pl.read_parquet(\"/content/drive/MyDrive/kddcup2023/data/preprocessed/common/product_03.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJmJYFIWAUqV"
   },
   "outputs": [],
   "source": [
    "co_visit_matrix = generate_co_visit_matrix(session_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjxxQyGDIGR8"
   },
   "outputs": [],
   "source": [
    "co_visit_matrix = filter_by_locale_availability(co_visit_matrix, product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXodoFWbucGI"
   },
   "outputs": [],
   "source": [
    "file_name = f\"co_visit_matrix_{VER}_for_train_or_eval.parquet\"\n",
    "co_visit_matrix.write_parquet(\"/content/drive/MyDrive/kddcup2023/data/interim/candidates/task1/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1703038943987,
     "user": {
      "displayName": "pp rich",
      "userId": "00371241177131396451"
     },
     "user_tz": -480
    },
    "id": "bT3wtCCCxSEa",
    "outputId": "65516580-e9e1-4ebb-d39b-3a8135fc7beb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item</th><th>candidate_item</th><th>lift</th><th>locale</th><th>lift_rank</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;0007440847&quot;</td><td>&quot;0008376107&quot;</td><td>0.4343</td><td>&quot;DE&quot;</td><td>1</td></tr><tr><td>&quot;0007440847&quot;</td><td>&quot;3608937145&quot;</td><td>0.133631</td><td>&quot;DE&quot;</td><td>2</td></tr><tr><td>&quot;0007440847&quot;</td><td>&quot;3608938184&quot;</td><td>0.117851</td><td>&quot;DE&quot;</td><td>3</td></tr><tr><td>&quot;0007440847&quot;</td><td>&quot;3608939849&quot;</td><td>0.058977</td><td>&quot;DE&quot;</td><td>4</td></tr><tr><td>&quot;0007440847&quot;</td><td>&quot;0261103563&quot;</td><td>0.051031</td><td>&quot;DE&quot;</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────────┬────────────────┬──────────┬────────┬───────────┐\n",
       "│ item       ┆ candidate_item ┆ lift     ┆ locale ┆ lift_rank │\n",
       "│ ---        ┆ ---            ┆ ---      ┆ ---    ┆ ---       │\n",
       "│ str        ┆ str            ┆ f64      ┆ str    ┆ u32       │\n",
       "╞════════════╪════════════════╪══════════╪════════╪═══════════╡\n",
       "│ 0007440847 ┆ 0008376107     ┆ 0.4343   ┆ DE     ┆ 1         │\n",
       "│ 0007440847 ┆ 3608937145     ┆ 0.133631 ┆ DE     ┆ 2         │\n",
       "│ 0007440847 ┆ 3608938184     ┆ 0.117851 ┆ DE     ┆ 3         │\n",
       "│ 0007440847 ┆ 3608939849     ┆ 0.058977 ┆ DE     ┆ 4         │\n",
       "│ 0007440847 ┆ 0261103563     ┆ 0.051031 ┆ DE     ┆ 5         │\n",
       "└────────────┴────────────────┴──────────┴────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_visit_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOtwZthQl0Ha"
   },
   "source": [
    "## MRR@100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sA9yoJBn2fC8"
   },
   "outputs": [],
   "source": [
    "train = pl.read_parquet(\"/content/drive/MyDrive/kddcup2023/data/preprocessed/task1/train_task1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ia9azZcl0P0"
   },
   "outputs": [],
   "source": [
    "# last_item\n",
    "last_item_list = []\n",
    "prev_items_list = train[\"prev_items\"].to_list()\n",
    "for prev_items in prev_items_list:\n",
    "    last_item_list.append(prev_items[-1])\n",
    "train = train.with_columns(pl.Series(name=\"last_item\", values=last_item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6Wcc4ci4TYa"
   },
   "outputs": [],
   "source": [
    "train = train[[\"session_id\", \"locale\", \"last_item\", \"next_item\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPSyGuvLIKIJ"
   },
   "outputs": [],
   "source": [
    "co_visit_matrix = pl.read_parquet(\"/content/drive/MyDrive/kddcup2023/data/interim/candidates/task1/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06aTXFJ9l0Sc"
   },
   "outputs": [],
   "source": [
    "# Merge candidate and add label\n",
    "dfs = []\n",
    "label_lists = []\n",
    "for locale in LOCALES:\n",
    "    df = train.filter(pl.col(\"locale\")==locale)\n",
    "    matrix = co_visit_matrix.filter(pl.col(\"locale\")==locale)\n",
    "    df = df.join(matrix, left_on=[\"locale\", \"last_item\"], right_on=[\"locale\", \"item\"], how=\"left\")\n",
    "    df = df.sort([\"session_id\", \"lift\"], descending=[False, True])\n",
    "    df = df.with_columns((pl.col(\"candidate_item\") == pl.col(\"next_item\")).cast(pl.Int8).alias(\"label\"))\n",
    "    label_lists.extend(df.groupby(\"session_id\", maintain_order=True).all()[\"label\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11502,
     "status": "ok",
     "timestamp": 1703039076698,
     "user": {
      "displayName": "pp rich",
      "userId": "00371241177131396451"
     },
     "user_tz": -480
    },
    "id": "F7KhQJN3l0Uy",
    "outputId": "99c3f052-0a07-4123-eee9-5f50f84452c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.23235\n"
     ]
    }
   ],
   "source": [
    "# MRR\n",
    "rr = 0\n",
    "for labels in label_lists:\n",
    "    labels = labels[:100]\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == 1:\n",
    "            rr += 1 / (i+1)\n",
    "            break\n",
    "mrr = rr / len(label_lists)\n",
    "print(\"MRR:\", round(mrr, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WePFxwftxF2S"
   },
   "source": [
    "# For test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glff-u5Y7vCm"
   },
   "outputs": [],
   "source": [
    "train1 = pl.read_parquet(DIR + \"data/preprocessed/task1/train_task1.parquet\")\n",
    "train2 = pl.read_parquet(DIR + \"data/preprocessed/task2/train_task2.parquet\")\n",
    "train1 = train1.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task1\").alias(\"session_id\")\n",
    ")\n",
    "train = pl.concat([train1, train2])\n",
    "\n",
    "test1_1 = pl.read_parquet(DIR + \"data/preprocessed/task1/test_task1_phase1.parquet\")\n",
    "test1_2 = pl.read_parquet(DIR + \"data/preprocessed/task1/test_task1_phase2.parquet\")\n",
    "test2_1 = pl.read_parquet(DIR + \"data/preprocessed/task2/test_task2_phase1.parquet\")\n",
    "test2_2 = pl.read_parquet(DIR + \"data/preprocessed/task2/test_task2_phase2.parquet\")\n",
    "test3_1 = pl.read_parquet(DIR + \"data/preprocessed/task3/test_task3_phase1.parquet\")\n",
    "test3_2 = pl.read_parquet(DIR + \"data/preprocessed/task3/test_task3_phase2.parquet\")\n",
    "test1_1 = test1_1.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task1\").alias(\"session_id\")\n",
    ")\n",
    "test1_2 = test1_2.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task1\").alias(\"session_id\")\n",
    ")\n",
    "test3_1 = test3_1.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task3\").alias(\"session_id\")\n",
    ")\n",
    "test3_2 = test3_2.with_columns(\n",
    "    (pl.col(\"session_id\") + \"_from_task3\").alias(\"session_id\")\n",
    ")\n",
    "test = pl.concat([test1_1, test1_2, test2_1, test2_2, test3_1, test3_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um9Y8XD09W2v"
   },
   "outputs": [],
   "source": [
    "# Append train's next_item to prev_items\n",
    "prev_items_list = train[\"prev_items\"].to_list()\n",
    "next_item_list = train[\"next_item\"].to_list()\n",
    "prev_items_list_updated = []\n",
    "for prev_items, next_item in zip(prev_items_list, next_item_list):\n",
    "    prev_items.append(next_item)\n",
    "    prev_items_list_updated.append(prev_items)\n",
    "\n",
    "train = train.with_columns(\n",
    "    pl.Series(name=\"prev_items\", values=prev_items_list_updated)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhFPqBM17vE5"
   },
   "outputs": [],
   "source": [
    "train = preprocess(train)\n",
    "test = preprocess(test)\n",
    "session_df = pl.concat([\n",
    "    train[\"prev_items\", \"locale\", \"session_id\", \"sequence_num\"],\n",
    "    test[\"prev_items\", \"locale\", \"session_id\", \"sequence_num\"],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lPMwOkfL_tZ"
   },
   "outputs": [],
   "source": [
    "product = pl.read_parquet(\"/content/drive/MyDrive/kddcup2023/data/preprocessed/common/product_03.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbwhO4n2MBCk"
   },
   "outputs": [],
   "source": [
    "co_visit_matrix = generate_co_visit_matrix(session_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTalWNeKMBZp"
   },
   "outputs": [],
   "source": [
    "co_visit_matrix = filter_by_locale_availability(co_visit_matrix, product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "De0bLV0nxM3T"
   },
   "outputs": [],
   "source": [
    "file_name = f\"co_visit_matrix_{VER}_for_inference.parquet\"\n",
    "co_visit_matrix.write_parquet(\"/content/drive/MyDrive/kddcup2023/data/interim/candidates/task1/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1705162212406,
     "user": {
      "displayName": "王晓",
      "userId": "03118875830758001304"
     },
     "user_tz": -480
    },
    "id": "293Toe7pxaBI",
    "outputId": "3e855c1f-86dc-41a8-df88-21790995982f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>item</th><th>candidate_item</th><th>lift</th><th>locale</th><th>lift_rank</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;0007440847&quot;</td><td>&quot;0544445783&quot;</td><td>0.7525</td><td>&quot;DE&quot;</td><td>1</td></tr><tr><td>&quot;0007440847&quot;</td><td>&quot;0008376107&quot;</td><td>0.400047</td><td>&quot;DE&quot;</td><td>2</td></tr><tr><td>&quot;0007440847&quot;</td><td>&quot;3608937145&quot;</td><td>0.133631</td><td>&quot;DE&quot;</td><td>3</td></tr><tr><td>&quot;0007440847&quot;</td><td>&quot;3608938184&quot;</td><td>0.102062</td><td>&quot;DE&quot;</td><td>4</td></tr><tr><td>&quot;0007440847&quot;</td><td>&quot;3608939849&quot;</td><td>0.053452</td><td>&quot;DE&quot;</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────────┬────────────────┬──────────┬────────┬───────────┐\n",
       "│ item       ┆ candidate_item ┆ lift     ┆ locale ┆ lift_rank │\n",
       "│ ---        ┆ ---            ┆ ---      ┆ ---    ┆ ---       │\n",
       "│ str        ┆ str            ┆ f64      ┆ str    ┆ u32       │\n",
       "╞════════════╪════════════════╪══════════╪════════╪═══════════╡\n",
       "│ 0007440847 ┆ 0544445783     ┆ 0.7525   ┆ DE     ┆ 1         │\n",
       "│ 0007440847 ┆ 0008376107     ┆ 0.400047 ┆ DE     ┆ 2         │\n",
       "│ 0007440847 ┆ 3608937145     ┆ 0.133631 ┆ DE     ┆ 3         │\n",
       "│ 0007440847 ┆ 3608938184     ┆ 0.102062 ┆ DE     ┆ 4         │\n",
       "│ 0007440847 ┆ 3608939849     ┆ 0.053452 ┆ DE     ┆ 5         │\n",
       "└────────────┴────────────────┴──────────┴────────┴───────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_visit_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bhuOxE0HS5C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
